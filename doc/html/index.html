<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3.1"/>
<title>RGBD360: Documentation Overview</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">RGBD360
   </div>
   <div id="projectbrief">This project contains the functionality to perform image acquisition, localization and mapping (SLAM) using an omnidirectional RGB-D sensor.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Documentation Overview </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="intro_sec"></a>
Introduction</h1>
<p>This is the documentation of the RGBD360 Project. This project integrates the functionality to do image acquisition, localization and mapping using an omnidirectional RGB-D sensor developed in INRIA Sophia-Antipolis by the team LAGADIC, and with the collaboration of the University of Malaga. This functionality comprises: reading and serializing the data streaming from the omnidirectional RGB-D sensor; registering frames based on a compact planar description of the scene (<a href="http://www.mrpt.org/pbmap">http://www.mrpt.org/pbmap</a>); loop closure detection; performing human-guided semi-automatic labelization of the scene; PbMap-based hybrid SLAM (i.e. using metric-topological-semantic information) with the omnidirectional RGB-D sensor moving freely with 6 DoF, or in planar movement with 3 DoF. Also, some visualization tools are provided to show the results from the above applications.</p>
<div class="image">
<img src="device+robot.png" alt="device+robot.png"/>
<div class="caption">
Omnidirectional RGB-D sensor and robot set-up.</div></div>
 <div class="image">
<img src="omnidirectional_rgbd_image2.png" alt="omnidirectional_rgbd_image2.png"/>
<div class="caption">
Omnidirectional RGB and Depth images.</div></div>
<p> <br/>
</p>
<h1><a class="anchor" id="project_sec"></a>
Project tree</h1>
<p>This project contains a previous one named 'OpenNI2_Grabber', which is used to access and read OpenNI2 sensors like Asus Xtion Pro Live (Asus XPL). Only the header files are used by 'RGBD360', thus it does not require to compile 'OpenNI2_Grabber'. However, this project can be compiled independently to use its test applications. The documentation of this project can be browsed in 'OpenNI2_Grabber/doc/html/index.html'. <br/>
</p>
<p>The main functionality provided by this project is implemented in a set of header files that are found in the directory 'include/'</p>
<ul>
<li><a class="el" href="Calib360_8h_source.html">Calib360.h</a></li>
<li><a class="el" href="Calibrator_8h_source.html">Calibrator.h</a></li>
<li><a class="el" href="Frame360_8h_source.html">Frame360.h</a></li>
<li><a class="el" href="Frame360__Visualizer_8h_source.html">Frame360_Visualizer.h</a></li>
<li><a class="el" href="RegisterRGBD360_8h_source.html">RegisterRGBD360.h</a></li>
<li><a class="el" href="FilterPointCloud_8h_source.html">FilterPointCloud.h</a></li>
<li><a class="el" href="Map360_8h_source.html">Map360.h</a></li>
<li><a class="el" href="Map360__Visualizer_8h_source.html">Map360_Visualizer.h</a></li>
<li><a class="el" href="TopologicalMap360_8h_source.html">TopologicalMap360.h</a></li>
<li><a class="el" href="LoopClosure360_8h_source.html">LoopClosure360.h</a></li>
<li><a class="el" href="GraphOptimizer_8h_source.html">GraphOptimizer.h</a></li>
<li><a class="el" href="Miscellaneous_8h_source.html">Miscellaneous.h</a></li>
</ul>
<p>The project applications are structured in different sections depending on its utility:</p>
<ul>
<li>Calibration/ <br/>
 -&gt; Contains the applications to calibrate the extrinsic parameters of the sensor.</li>
<li>Grabber/ <br/>
 -&gt; Grab and serialize the omnidirectional RGB-D image stream.</li>
<li>Labelization/ <br/>
 -&gt; Write semantic labels on the images.</li>
<li>Registration/ <br/>
 -&gt; Register (align) pairs of spherical RGB-D images. Odometry applications.</li>
<li>SLAM/ <br/>
 -&gt; Hybrid pose-graph SLAM using metric-topological-semantic information.</li>
<li>Visualization/ <br/>
 -&gt; Load a serialized image stream. Load and build the spheres.</li>
</ul>
<h1><a class="anchor" id="dependencies_sec"></a>
Dependencies</h1>
<p>This project depends on several open-source libraries to build the whole solution. The main dependencies are:</p>
<ul>
<li>OpenCV: <a href="http://opencv.org/">http://opencv.org/</a> (Installing the binaries is recommended. This project has also been tested with the version 2.4.5 compiled from sources.)</li>
<li>PCL: <a href="http://pointclouds.org/">http://pointclouds.org/</a> (This project uses the version of Eduardo Fernandez, which can be downloaded from <a href="https://github.com/EduFdez/pcl.git">https://github.com/EduFdez/pcl.git</a>)</li>
<li>MRPT: <a href="http://www.mrpt.org/">http://www.mrpt.org/</a> (This project uses the version of Eduardo Fernandez, which can be downloaded from <a href="https://github.com/EduFdez/mrpt.git">https://github.com/EduFdez/mrpt.git</a>)</li>
<li>Eigen: <a href="http://eigen.tuxfamily.org">http://eigen.tuxfamily.org</a> (Install the current version for your system)</li>
</ul>
<p>This project also contains some third party code and dependencies which are provided here to facilitate compilation and to avoid possible compatibility issues in the future. They are found in the directory 'OpenNI2_Grabber/third_party/'. These dependencies are:</p>
<ul>
<li>OpenNI2: <a href="http://www.openni.org/">http://www.openni.org/</a> (This library is needed to open and read the sensor, it is not required to work with data already recorded in datasets.)</li>
<li>CLAMS: <a href="http://www.alexteichman.com/octo/clams/">http://www.alexteichman.com/octo/clams/</a> (This project performs the intrinsic calibration of RGB-D sensors (see "paper"). It is used here to undistort the depth images captured with our device.)</li>
</ul>
<h1><a class="anchor" id="install_sec"></a>
Installation</h1>
<p>This project has been implemented and tested in Ubuntu 12.04 and 13.04. This project contains a CMalelists.txt file to facilitate the integration of the different dependencies. Thus, the software CMake is required to produce the configuration file 'Makefile' for compilation. To compile the source code the above dependencies must be installed first (make sure that their dependencies are also installed, for that, follow the instructions given in the website of each library). MRPT and PCL must be compiled using the sources referred above. A version of OpenNI2 (downloaded on November 8th, 2013) is provided within this project to avoid possible compatibility problems in the future. After that, the following steps will guide you to compile the project. </p>
<pre class="fragment">cd yourPathTo/RGBD360
</pre> <pre class="fragment">  - Generate the Makefile with CMake.
       -# Open CMake (the following instructions are for cmake-gui).
       -# Set the source directory to RGBD360 and the build directory to RGBD360/build.
       -# Set OpenCV_DIR, PCL_DIR and MRPT_DIR to the directories containing the built packages from OpenCV, PCL and MRPT respectively.
       -# Set the application packages to build (Grabber, Visualizer, etc.). To reckon which packages you need, go to the next section to find out a more detailed description of each package's applications.
       -# Configure.
       -# Generate.

  - Compile the RGBD360 project.
       -# Go to the directory RGBD360/build/
       -# Compile with 'make'.
</pre><p>Important notes:</p>
<ul>
<li>the library Boost is a dependency of PCL, the version 1.46 (or newer) of Boost is required here.</li>
<li>the executable files that access the omnidirectional RGB-D sensor link dynamically against the library OpenNI2, this requires that those executables and the OpenNI2 library files are found in the same directory. Thus, if you do not build the project in the default 'build/' directory, then you must copy the original content of the 'build/' directory to the directory containing your executables (e.g. RGBD30_Grabber, or OnlineCalibratorRGBD360).</li>
<li>compilation errors occur when different versions of the dependencies (OpenCV, PCL or MRPT) are installed in the machine and they are not correctly specified in CMake (so that include and lib files of different versions are mixed). To solve this problem, make sure that the paths given in CMake-GUI refer to the correct libraries.</li>
</ul>
<h1><a class="anchor" id="usage_sec"></a>
Software usage</h1>
<p>After compiling this project, a number of directories containing the different application packages will be created. The applications of these packages are described below (<b>a brief description of each application and its syntaxis is shown on executing ./application -h'</b>): </p>
<h2><a class="anchor" id="Calibration"></a>
Calibration</h2>
<p>This package contains the applications to calibrate the extrinsic parameters of the sensor</p>
<pre class="fragment">./Calibrator
</pre><p>This program calibrates the extrinsic parameters of the omnidirectional RGB-D device. The key idea is to match planar observations, assuming that the dominant planes (e.g. walls, ceiling or floor) can be observed at the same time by several contiguous sensors (take into account that the overlapping between the different sensors is negligible). The planes are segmented from the depth images using a region growing approach (thus, color information is not used for calibration). These planes are matched automatically according to the device construction specifications, which are refined by this program. This program opens the sensor, which has to be moved to take different plane observations at different angles and distances. When enough information has been collected, a Gauss-Newtown optimization is launched to obtain the extrinsic calibration, which can be saved if the user demands it after visual validation of the calibrated images.</p>
<h2><a class="anchor" id="Grabber"></a>
Grabber</h2>
<p>Read the omnidirectional RGB-D image stream from the RGBD360 sensor.</p>
<pre class="fragment">./RGBD360_Grabber &lt;pathToSaveToDisk&gt;
</pre><p>This program accesses the omnidirectional RGB-D sensor, and reads the image streaming it captures. The image stream is recorded in the path specified by the user. </p>
<h2><a class="anchor" id="Labelization"></a>
Labelization</h2>
<p>This package contains applications to annotate semantic labels on the spherical RGB-D images and on the planes extracted from them.</p>
<pre class="fragment">./LabelizeFrame &lt;pathToPbMap&gt;
</pre><p>This program loads a PbMap (a its corresponding point cloud) and asks the user to labelize the planes before saving the annotated PbMap to disk.</p>
<pre class="fragment">./LabelizeSequence &lt;pathToFolderWithSpheres&gt;
</pre><p>This program loads a stream of previously built spheres (PbMap+PointCloud) partially labelized, and expands the labels by doing consecutive frame registration.</p>
<h2><a class="anchor" id="Registration"></a>
Registration</h2>
<p>This package contains applications based on the registration of pairs of RGB-D images through the matching and alignment of the PbMaps extracted from them.</p>
<pre class="fragment">./OdometryRGBD360 &lt;pathToRawRGBDImagesDir&gt; &lt;pathToResults&gt; &lt;sampleStream&gt;
</pre><p>This program performs PbMap-based Odometry from the data stream recorded by an omnidirectional RGB-D sensor.</p>
<pre class="fragment">./RegisterPairRGBD360 &lt;frame360_1_1.bin&gt; &lt;frame360_1_2.bin&gt;
</pre><p>This program loads two raw omnidireactional RGB-D images and aligns them using PbMap-based registration.</p>
<h2><a class="anchor" id="SLAM"></a>
SLAM</h2>
<p>This package is dedicated to SLAM applications.</p>
<pre class="fragment">./SphereGraphSLAM &lt;pathToRawRGBDImagesDir&gt;
</pre><p>This program performs metric-topological SLAM from the data stream recorded by an omnidirectional RGB-D sensor. The directory containing the input raw omnidireactional RGB-D images (.frame360 files) has to be specified.</p>
<h2><a class="anchor" id="Visualization"></a>
Visualization</h2>
<p>This package contains applications to read and visualize the spherical RGB-D images, and the point clouds and PbMaps built from them.</p>
<pre class="fragment">./LoadFrame360 &lt;pathToFrame360.bin&gt;
</pre><p>This program loads a Frame360.bin (an omnidirectional RGB-D image in raw binary format). It builds the pointCloud and creates a PbMap from it. The spherical frame is shown: the keys 'k' and 'l' are used to switch between visualization modes.</p>
<pre class="fragment">./LoadSequence &lt;mode&gt; &lt;pathToData&gt; &lt;pathToResultsFolder&gt;
</pre><p>This program loads a sequence of observations 'RGBD360.bin' and visualizes and/or saves the spherical images, the pointCloud or the PbMap extracted from it according to the command options. <br/>
 mode = 1 -&gt; Show the reconstructed spherical images <br/>
 mode = 2 -&gt; Show and save the reconstructed spherical images <br/>
 mode = 3 -&gt; Show the reconstructed PointCloud and the PbMap <br/>
 mode = 4 -&gt; Save the reconstructed PointCloud and the PbMap <br/>
 mode = 5 -&gt; Show a video streaming of the reconstructed PointCloud <br/>
</p>
<pre class="fragment">./LoadSphere &lt;pathToPointCloud&gt; &lt;pathToPbMap&gt;
</pre><p>This program loads the pointCloud and the PbMap from a RGBD360 observation. <br/>
 <br/>
</p>
<dl class="section author"><dt>Author</dt><dd>Eduardo Fernandez-Moral </dd></dl>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Wed Dec 18 2013 13:08:19 for RGBD360 by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.3.1
</small></address>
</body>
</html>
